{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db4027a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import gc\n",
    "import datetime\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ROOT = '/Users/wuqianran/Desktop/bigdata_finalproject/final'\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f252a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "\n",
    "    def set_table_dtypes(df):\n",
    "        for col in df.columns:\n",
    "            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Int64))\n",
    "            elif col in [\"date_decision\"]:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date))\n",
    "            elif col[-1] in (\"P\", \"A\"):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Float64))\n",
    "            elif col[-1] in (\"M\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.String))\n",
    "            elif col[-1] in (\"D\",):\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Date))\n",
    "        return df\n",
    "\n",
    "    def handle_dates(df):\n",
    "        for col in df.columns:\n",
    "            if col[-1] in (\"D\",):\n",
    "                df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))  #!!?\n",
    "                df = df.with_columns(pl.col(col).dt.total_days()) # t - t-1\n",
    "        df = df.drop(\"date_decision\", \"MONTH\")\n",
    "        return df\n",
    "\n",
    "    def filter_cols(df):\n",
    "        for col in df.columns:\n",
    "            if col not in [\"target\", \"case_id\", \"WEEK_NUM\"]:\n",
    "                isnull = df[col].is_null().mean()\n",
    "                if isnull > 0.95:\n",
    "                    df = df.drop(col)\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if (col not in [\"target\", \"case_id\", \"WEEK_NUM\"]) & (df[col].dtype == pl.String):\n",
    "                freq = df[col].n_unique()\n",
    "                if (freq == 1) | (freq > 200):\n",
    "                    df = df.drop(col)\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "class Aggregator:\n",
    "    # Please add or subtract features yourself, be aware that too many features will take up too much space.\n",
    "    def num_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"P\", \"A\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        # expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n",
    "        expr_median = [pl.median(col).alias(f\"median_{col}\") for col in cols]\n",
    "        expr_var = [pl.var(col).alias(f\"var_{col}\") for col in cols]\n",
    "\n",
    "        return expr_max  + expr_mean \n",
    "\n",
    "    def date_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"D\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        # expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        # expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n",
    "        expr_median = [pl.median(col).alias(f\"median_{col}\") for col in cols]\n",
    "\n",
    "        return expr_max  + expr_mean \n",
    "\n",
    "    def str_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"M\",)]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        # expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        # expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        # expr_count = [pl.count(col).alias(f\"count_{col}\") for col in cols]\n",
    "        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n",
    "        return expr_max  + expr_mean\n",
    "    \n",
    "    def other_expr(df):\n",
    "        cols = [col for col in df.columns if col[-1] in (\"T\", \"L\")]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        # expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        # expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n",
    "        return expr_max  + expr_mean\n",
    "\n",
    "    def count_expr(df):\n",
    "        cols = [col for col in df.columns if \"num_group\" in col]\n",
    "        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n",
    "        # expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n",
    "        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n",
    "        # expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n",
    "        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n",
    "        return expr_max + expr_mean\n",
    "\n",
    "    def get_exprs(df):\n",
    "        exprs = Aggregator.num_expr(df) + \\\n",
    "                Aggregator.date_expr(df) + \\\n",
    "                Aggregator.str_expr(df) + \\\n",
    "                Aggregator.other_expr(df) + \\\n",
    "                Aggregator.count_expr(df)\n",
    "\n",
    "        return exprs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17d92da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path, depth=None):\n",
    "    df = pl.read_parquet(path)\n",
    "    df = df.pipe(Pipeline.set_table_dtypes)\n",
    "    if depth in [1,2]:\n",
    "        df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df)) \n",
    "    return df\n",
    "\n",
    "\n",
    "def read_files(regex_path, depth=None):\n",
    "    chunks = []\n",
    "    \n",
    "    for path in glob(str(regex_path)):\n",
    "        df = pl.read_parquet(path)\n",
    "        df = df.pipe(Pipeline.set_table_dtypes)\n",
    "        if depth in [1, 2]:\n",
    "            df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n",
    "        chunks.append(df)\n",
    "    \n",
    "    df = pl.concat(chunks, how=\"vertical_relaxed\")\n",
    "    df = df.unique(subset=[\"case_id\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5c3674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_eng(df_base, depth_0, depth_1, depth_2):\n",
    "    df_base = (\n",
    "        df_base\n",
    "        .with_columns(\n",
    "            month_decision = pl.col(\"date_decision\").dt.month(),\n",
    "            weekday_decision = pl.col(\"date_decision\").dt.weekday(),\n",
    "        )\n",
    "    )\n",
    "    for i, df in enumerate(depth_0 + depth_1 + depth_2):\n",
    "        df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n",
    "    df_base = df_base.pipe(Pipeline.handle_dates)\n",
    "    return df_base\n",
    "\n",
    "\n",
    "def to_pandas(df_data, cat_cols=None):\n",
    "    df_data = df_data.to_pandas()\n",
    "    if cat_cols is None:\n",
    "        cat_cols = list(df_data.select_dtypes(\"object\").columns)\n",
    "    df_data[cat_cols] = df_data[cat_cols].astype(\"category\")\n",
    "    return df_data, cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57f75714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if str(col_type)==\"category\":\n",
    "            continue\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            continue\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21980cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 5s, sys: 1min 59s, total: 4min 5s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ROOT            = Path(ROOT)\n",
    "\n",
    "TRAIN_DIR       = ROOT / \"parquet_files\" / \"train\"\n",
    "TEST_DIR        = ROOT / \"parquet_files\" / \"test\"\n",
    "\n",
    "data_store = {\n",
    "    \"df_base\": read_file(TRAIN_DIR / \"train_base.parquet\"),\n",
    "    \"depth_0\": [\n",
    "        read_file(TRAIN_DIR / \"train_static_cb_0.parquet\"),\n",
    "        read_files(TRAIN_DIR / \"train_static_0_*.parquet\"),\n",
    "    ],\n",
    "    \"depth_1\": [\n",
    "        read_files(TRAIN_DIR / \"train_applprev_1_*.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_a_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_b_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_tax_registry_c_1.parquet\", 1),\n",
    "        read_files(TRAIN_DIR / \"train_credit_bureau_a_1_*.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_credit_bureau_b_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_other_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_person_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_deposit_1.parquet\", 1),\n",
    "        read_file(TRAIN_DIR / \"train_debitcard_1.parquet\", 1),\n",
    "    ],\n",
    "    \"depth_2\": [\n",
    "        read_file(TRAIN_DIR / \"train_credit_bureau_b_2.parquet\", 2),\n",
    "        read_files(TRAIN_DIR / \"train_credit_bureau_a_2_*.parquet\", 2),\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "648fdd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape:\t (1526659, 720)\n",
      "CPU times: user 14.2 s, sys: 8.55 s, total: 22.7 s\n",
      "Wall time: 15.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3869"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_train = feature_eng(**data_store)\n",
    "print(\"train data shape:\\t\", df_train.shape)\n",
    "del data_store\n",
    "df_train = df_train.pipe(Pipeline.filter_cols)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35b7b547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: polars in ./new_venv/lib/python3.9/site-packages (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9875db5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_encoding_cols = df_train.select(pl.selectors.by_dtype([pl.String, pl.Boolean, pl.Categorical])).columns\n",
    "\n",
    "mappings = {}\n",
    "for col in cnt_encoding_cols:\n",
    "    mappings[col] = df_train.group_by(col).len()\n",
    "\n",
    "df_train_lazy = df_train.select(mappings.keys()).lazy()\n",
    "# df_train_lazy = pl.LazyFrame(df_train.select('case_id'))\n",
    "\n",
    "for col, mapping in mappings.items():\n",
    "    remapping = {category: count for category, count in mapping.rows()}\n",
    "    remapping[None] = -2\n",
    "    expr = pl.col(col).replace(\n",
    "                remapping,\n",
    "                default=-1,\n",
    "            )\n",
    "    df_train_lazy = df_train_lazy.with_columns(expr.alias(col + '_cnt'))\n",
    "    del col, mapping, remapping\n",
    "    gc.collect()\n",
    "\n",
    "del mappings\n",
    "transformed_train = df_train_lazy.collect()\n",
    "\n",
    "df_train = pl.concat([df_train, transformed_train.select(\"^*cnt$\")], how='horizontal')\n",
    "del transformed_train, cnt_encoding_cols\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c08fabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 5809.23 MB\n",
      "Memory usage after optimization is: 2137.36 MB\n",
      "Decreased by 63.2%\n",
      "train data shape:\t (1526659, 564)\n",
      "Use these ['case_id', 'WEEK_NUM', 'target', 'month_decision', 'weekday_decision', 'credamount_770A', 'applicationcnt_361L', 'applications30d_658L', 'applicationscnt_1086L', 'applicationscnt_464L', 'applicationscnt_867L', 'clientscnt_1022L', 'clientscnt_100L', 'clientscnt_1071L', 'clientscnt_1130L', 'clientscnt_157L', 'clientscnt_257L', 'clientscnt_304L', 'clientscnt_360L', 'clientscnt_493L', 'clientscnt_533L', 'clientscnt_887L', 'clientscnt_946L', 'deferredmnthsnum_166L', 'disbursedcredamount_1113A', 'downpmt_116A', 'homephncnt_628L', 'isbidproduct_1095L', 'mobilephncnt_593L', 'numactivecreds_622L', 'numactivecredschannel_414L', 'numactiverelcontr_750L', 'numcontrs3months_479L', 'numnotactivated_1143L', 'numpmtchanneldd_318L', 'numrejects9m_859L', 'sellerplacecnt_915L', 'max_mainoccupationinc_384A', 'max_birth_259D', 'mean_persontype_1072L', 'description_5085714M_cnt', 'education_1103M_cnt', 'maritalst_893M_cnt', 'maritalst_385M_cnt', 'requesttype_4525192L_cnt', 'bankacctype_710L_cnt', 'cardtype_51L_cnt', 'credtype_322L_cnt', 'disbursementtype_67L_cnt', 'equalitydataagreement_891L_cnt', 'isbidproduct_1095L_cnt', 'lastapprcommoditycat_1041M_cnt', 'lastcancelreason_561M_cnt', 'lastrejectcommoditycat_161M_cnt', 'lastrejectcommodtypec_5251769M_cnt', 'lastrejectreason_759M_cnt', 'lastst_736L_cnt', 'paytype1st_925L_cnt', 'twobodfilling_608L_cnt', 'typesuite_864L_cnt', 'max_cancelreason_3545846M_cnt', 'max_education_1138M_cnt', 'max_postype_4733339M_cnt', 'max_credacc_status_367L_cnt', 'max_credtype_587L_cnt', 'max_familystate_726L_cnt', 'max_isbidproduct_390L_cnt', 'max_isdebitcard_527L_cnt', 'max_status_219L_cnt', 'max_collaterals_typeofguarante_669M_cnt', 'max_classificationofcontr_400M_cnt', 'max_contractst_545M_cnt', 'max_contractst_964M_cnt', 'max_financialinstitution_382M_cnt', 'max_financialinstitution_591M_cnt', 'max_purposeofcred_874M_cnt', 'max_subjectrole_93M_cnt', 'max_education_927M_cnt', 'max_empladdr_district_926M_cnt', 'max_language1_981M_cnt', 'max_contaddr_matchlist_1032L_cnt', 'max_contaddr_smempladdr_334L_cnt', 'max_empl_employedtotal_800L_cnt', 'max_empl_industry_691L_cnt', 'max_familystate_447L_cnt', 'max_housetype_905L_cnt', 'max_incometype_1044T_cnt', 'max_role_1084L_cnt', 'max_safeguarantyflag_411L_cnt', 'max_sex_738L_cnt', 'max_type_25L_cnt', 'max_collaterals_typeofguarante_359M_cnt']\n",
      "####### NAN count = 0\n",
      "####### NAN count = 1389663\n",
      "Use these ['assignmentdate_4527235D', 'pmtaverage_4527227A', 'pmtcount_4527229L']\n",
      "####### NAN count = 1411681\n",
      "####### NAN count = 918788\n",
      "Use these ['mean_contractsum_5085717L']\n",
      "####### NAN count = 1369330\n",
      "Use these ['dateofbirth_337D', 'days180_256L', 'days30_165L', 'days360_512L', 'firstquarter_103L', 'fourthquarter_440L', 'secondquarter_766L', 'thirdquarter_1082L', 'max_debtoutstand_525A', 'max_debtoverdue_47A', 'max_refreshdate_3813885D', 'mean_refreshdate_3813885D']\n",
      "####### NAN count = 140968\n",
      "####### NAN count = 1383070\n",
      "####### NAN count = 1380253\n",
      "Use these ['pmtscount_423L', 'pmtssum_45A']\n",
      "####### NAN count = 954021\n",
      "####### NAN count = 806659\n",
      "####### NAN count = 866332\n",
      "####### NAN count = 1301747\n",
      "####### NAN count = 418178\n",
      "Use these ['amtinstpaidbefduel24m_4187115A', 'numinstlswithdpd5_4187116L']\n",
      "####### NAN count = 561124\n",
      "Use these ['annuitynextmonth_57A', 'currdebt_22A', 'currdebtcredtyperange_828A', 'numinstls_657L', 'totalsettled_863A']\n",
      "####### NAN count = 4\n",
      "Use these ['mindbddpdlast24m_3658935P']\n",
      "####### NAN count = 613202\n",
      "####### NAN count = 948244\n",
      "Use these ['mindbdtollast24m_4525191P']\n",
      "####### NAN count = 972827\n",
      "####### NAN count = 467175\n",
      "Use these ['avginstallast24m_3658937A', 'maxinstallast24m_3658928A']\n",
      "####### NAN count = 624875\n",
      "####### NAN count = 1364150\n",
      "####### NAN count = 757006\n",
      "####### NAN count = 841181\n",
      "####### NAN count = 1026987\n",
      "####### NAN count = 455190\n",
      "####### NAN count = 460822\n",
      "Use these ['commnoinclast6m_3546845L', 'maxdpdfrom6mto36m_3546853P']\n",
      "####### NAN count = 343375\n",
      "####### NAN count = 833735\n",
      "####### NAN count = 1392841\n",
      "####### NAN count = 887659\n",
      "Use these ['daysoverduetolerancedd_3976961L', 'numinsttopaygr_769L']\n",
      "####### NAN count = 452594\n",
      "####### NAN count = 977119\n",
      "Use these ['eir_270L']\n",
      "####### NAN count = 190833\n",
      "####### NAN count = 859214\n",
      "####### NAN count = 482103\n",
      "####### NAN count = 1334357\n",
      "####### NAN count = 453587\n",
      "Use these ['lastapplicationdate_877D', 'mean_creationdate_885D', 'mean_isbidproduct_390L', 'max_num_group1']\n",
      "####### NAN count = 305137\n",
      "Use these ['lastapprcredamount_781A', 'lastapprdate_640D']\n",
      "####### NAN count = 442041\n",
      "####### NAN count = 977975\n",
      "Use these ['lastrejectcredamount_222A', 'lastrejectdate_50D']\n",
      "####### NAN count = 769046\n",
      "####### NAN count = 511255\n",
      "Use these ['mastercontrelectronic_519L', 'mastercontrexist_109L', 'maxannuity_159A', 'maxdebt4_972A', 'maxdpdlast24m_143P', 'maxdpdlast3m_392P', 'maxdpdtolerance_374P']\n",
      "####### NAN count = 306019\n",
      "####### NAN count = 960953\n",
      "####### NAN count = 705504\n",
      "####### NAN count = 876276\n",
      "####### NAN count = 826000\n",
      "####### NAN count = 829402\n",
      "####### NAN count = 1032856\n",
      "####### NAN count = 766958\n",
      "####### NAN count = 1129330\n",
      "Use these ['numinstpaidearly_338L', 'numinstpaidearly5d_1087L', 'numinstpaidlate1d_3546852L']\n",
      "####### NAN count = 452593\n",
      "####### NAN count = 455081\n",
      "Use these ['numinstlsallpaid_934L']\n",
      "####### NAN count = 445669\n",
      "Use these ['numinstlswithdpd10_728L', 'numinstlswithoutdpd_562L']\n",
      "####### NAN count = 456495\n",
      "Use these ['numinstpaid_4499208L']\n",
      "####### NAN count = 847191\n",
      "####### NAN count = 446983\n",
      "Use these ['numinstregularpaidest_4493210L', 'numinstpaidearly5dest_4493211L', 'sumoutstandtotalest_4493215A']\n",
      "####### NAN count = 840646\n",
      "####### NAN count = 669186\n",
      "####### NAN count = 455612\n",
      "Use these ['pctinstlsallpaidearl3d_427L', 'pctinstlsallpaidlate1d_3546856L']\n",
      "####### NAN count = 458738\n",
      "####### NAN count = 461362\n",
      "####### NAN count = 459827\n",
      "####### NAN count = 460079\n",
      "####### NAN count = 44954\n",
      "####### NAN count = 78526\n",
      "####### NAN count = 131888\n",
      "####### NAN count = 181122\n",
      "####### NAN count = 223240\n",
      "####### NAN count = 445320\n",
      "####### NAN count = 3\n",
      "####### NAN count = 1174211\n",
      "####### NAN count = 1374886\n",
      "Use these ['mean_actualdpd_943P']\n",
      "####### NAN count = 305154\n",
      "Use these ['max_annuity_853A', 'mean_annuity_853A']\n",
      "####### NAN count = 308739\n",
      "Use these ['mean_credacc_actualbalance_314A', 'mean_credacc_maxhisbal_375A', 'mean_credacc_minhisbal_90A', 'mean_credacc_transactions_402L']\n",
      "####### NAN count = 1273086\n",
      "Use these ['max_credacc_credlmt_575A', 'max_credamount_590A', 'max_downpmt_134A', 'mean_credacc_credlmt_575A', 'mean_credamount_590A', 'mean_downpmt_134A']\n",
      "####### NAN count = 307441\n",
      "Use these ['max_currdebt_94A', 'mean_currdebt_94A']\n",
      "####### NAN count = 419006\n",
      "Use these ['max_mainoccupationinc_437A', 'mean_mainoccupationinc_437A']\n",
      "####### NAN count = 306361\n",
      "Use these ['mean_maxdpdtolerance_577P']\n",
      "####### NAN count = 450969\n",
      "Use these ['max_outstandingdebt_522A', 'mean_outstandingdebt_522A']\n",
      "####### NAN count = 420383\n",
      "Use these ['mean_revolvingaccount_394A']\n",
      "####### NAN count = 1273082\n",
      "Use these ['max_approvaldate_319D', 'mean_approvaldate_319D']\n",
      "####### NAN count = 442999\n",
      "Use these ['max_dateactivated_425D', 'mean_dateactivated_425D']\n",
      "####### NAN count = 454678\n",
      "Use these ['max_dtlastpmt_581D', 'mean_dtlastpmt_581D']\n",
      "####### NAN count = 703840\n",
      "Use these ['max_dtlastpmtallstes_3545839D', 'mean_dtlastpmtallstes_3545839D']\n",
      "####### NAN count = 548987\n",
      "Use these ['max_employedfrom_700D']\n",
      "####### NAN count = 559169\n",
      "Use these ['max_firstnonzeroinstldate_307D', 'mean_firstnonzeroinstldate_307D']\n",
      "####### NAN count = 334873\n",
      "Use these ['mean_byoccupationinc_3656910L']\n",
      "####### NAN count = 961606\n",
      "Use these ['mean_childnum_21L']\n",
      "####### NAN count = 552766\n",
      "Use these ['max_pmtnum_8L', 'mean_pmtnum_8L']\n",
      "####### NAN count = 321446\n",
      "####### NAN count = 1182972\n",
      "Use these ['max_amount_4527230A', 'max_recorddate_4527225D', 'max_num_group1_3']\n",
      "####### NAN count = 1068725\n",
      "Use these ['mean_amount_4917619A', 'max_deductiondate_4917603D', 'mean_deductiondate_4917603D', 'max_num_group1_4']\n",
      "####### NAN count = 1375927\n",
      "Use these ['max_pmtamount_36A', 'max_processingdate_168D', 'mean_processingdate_168D', 'max_num_group1_5']\n",
      "####### NAN count = 1044394\n",
      "Use these ['mean_credlmt_230A']\n",
      "####### NAN count = 1036944\n",
      "Use these ['mean_credlmt_935A']\n",
      "####### NAN count = 603001\n",
      "Use these ['mean_pmts_dpd_1073P', 'mean_dpdmaxdatemonth_89T', 'mean_dpdmaxdateyear_596T']\n",
      "####### NAN count = 263166\n",
      "Use these ['max_pmts_dpd_303P', 'mean_dpdmax_757P', 'max_dpdmaxdatemonth_442T', 'max_dpdmaxdateyear_896T', 'mean_dpdmaxdatemonth_442T', 'mean_dpdmaxdateyear_896T', 'mean_pmts_dpd_303P']\n",
      "####### NAN count = 514070\n",
      "Use these ['mean_instlamount_768A']\n",
      "####### NAN count = 606920\n",
      "Use these ['mean_instlamount_852A']\n",
      "####### NAN count = 1136162\n",
      "Use these ['mean_monthlyinstlamount_332A']\n",
      "####### NAN count = 263233\n",
      "Use these ['max_monthlyinstlamount_674A', 'mean_monthlyinstlamount_674A']\n",
      "####### NAN count = 517511\n",
      "Use these ['mean_outstandingamount_354A']\n",
      "####### NAN count = 545885\n",
      "Use these ['mean_outstandingamount_362A']\n",
      "####### NAN count = 636453\n",
      "Use these ['mean_overdueamount_31A']\n",
      "####### NAN count = 512650\n",
      "Use these ['mean_overdueamount_659A', 'mean_numberofoverdueinstls_725L']\n",
      "####### NAN count = 263171\n",
      "Use these ['mean_overdueamountmax2_14A', 'mean_totaloutstanddebtvalue_39A', 'mean_dateofcredend_289D', 'mean_dateofcredstart_739D', 'max_lastupdate_1112D', 'mean_lastupdate_1112D', 'mean_numberofcontrsvalue_258L', 'mean_numberofoverdueinstlmax_1039L', 'mean_overdueamountmaxdatemonth_365T', 'mean_overdueamountmaxdateyear_2T', 'mean_pmts_overdue_1140A', 'max_pmts_month_158T', 'max_pmts_year_1139T', 'mean_pmts_month_158T', 'mean_pmts_year_1139T']\n",
      "####### NAN count = 262653\n",
      "Use these ['mean_overdueamountmax2_398A', 'max_dateofcredend_353D', 'max_dateofcredstart_181D', 'mean_dateofcredend_353D', 'max_numberofoverdueinstlmax_1151L', 'mean_numberofoverdueinstlmax_1151L']\n",
      "####### NAN count = 512590\n",
      "Use these ['mean_overdueamountmax_35A', 'max_overdueamountmaxdatemonth_284T', 'max_overdueamountmaxdateyear_994T', 'mean_overdueamountmaxdatemonth_284T', 'mean_overdueamountmaxdateyear_994T', 'mean_pmts_overdue_1152A']\n",
      "####### NAN count = 513987\n",
      "Use these ['max_residualamount_488A']\n",
      "####### NAN count = 1039597\n",
      "Use these ['mean_residualamount_856A']\n",
      "####### NAN count = 606900\n",
      "Use these ['max_totalamount_6A', 'mean_totalamount_6A']\n",
      "####### NAN count = 545855\n",
      "Use these ['mean_totalamount_996A']\n",
      "####### NAN count = 636448\n",
      "Use these ['mean_totaldebtoverduevalue_718A', 'mean_totaloutstanddebtvalue_668A', 'mean_numberofcontrsvalue_358L']\n",
      "####### NAN count = 297072\n",
      "Use these ['max_dateofrealrepmt_138D', 'mean_dateofrealrepmt_138D']\n",
      "####### NAN count = 512961\n",
      "Use these ['max_lastupdate_388D', 'mean_lastupdate_388D']\n",
      "####### NAN count = 512591\n",
      "Use these ['max_numberofoverdueinstlmaxdat_148D']\n",
      "####### NAN count = 802351\n",
      "Use these ['mean_numberofoverdueinstlmaxdat_641D']\n",
      "####### NAN count = 1012361\n",
      "Use these ['mean_overdueamountmax2date_1002D']\n",
      "####### NAN count = 806653\n",
      "Use these ['max_overdueamountmax2date_1142D']\n",
      "####### NAN count = 1007594\n",
      "Use these ['mean_annualeffectiverate_199L']\n",
      "####### NAN count = 1237917\n",
      "Use these ['mean_annualeffectiverate_63L']\n",
      "####### NAN count = 1270160\n",
      "Use these ['mean_nominalrate_281L']\n",
      "####### NAN count = 822517\n",
      "Use these ['max_nominalrate_498L', 'mean_nominalrate_498L']\n",
      "####### NAN count = 745109\n",
      "Use these ['max_numberofinstls_229L', 'mean_numberofinstls_229L']\n",
      "####### NAN count = 545898\n",
      "Use these ['mean_numberofinstls_320L']\n",
      "####### NAN count = 636545\n",
      "Use these ['mean_numberofoutstandinstls_520L']\n",
      "####### NAN count = 545895\n",
      "Use these ['mean_numberofoutstandinstls_59L']\n",
      "####### NAN count = 636544\n",
      "Use these ['max_numberofoverdueinstls_834L', 'mean_numberofoverdueinstls_834L']\n",
      "####### NAN count = 512657\n",
      "Use these ['max_periodicityofpmts_1102L', 'mean_periodicityofpmts_1102L']\n",
      "####### NAN count = 561307\n",
      "Use these ['mean_periodicityofpmts_837L']\n",
      "####### NAN count = 649082\n",
      "Use these ['mean_prolongationcount_1120L']\n",
      "####### NAN count = 1436524\n",
      "Use these ['mean_num_group1_6']\n",
      "####### NAN count = 140386\n",
      "Use these ['max_empl_employedfrom_271D']\n",
      "####### NAN count = 959958\n",
      "Use these ['mean_contaddr_matchlist_1032L', 'mean_contaddr_smempladdr_334L']\n",
      "####### NAN count = 441\n",
      "####### NAN count = 935626\n",
      "####### NAN count = 2\n",
      "Use these ['mean_amount_416A', 'mean_openingdate_313D', 'max_num_group1_10']\n",
      "####### NAN count = 1421548\n",
      "Use these ['mean_openingdate_857D']\n",
      "####### NAN count = 1421572\n",
      "Use these ['max_num_group1_11']\n",
      "####### NAN count = 1414887\n",
      "Use these ['mean_collater_valueofguarantee_1124L']\n",
      "####### NAN count = 262659\n",
      "Use these ['mean_collater_valueofguarantee_876L']\n",
      "####### NAN count = 512884\n",
      "Use these ['max_pmts_month_706T', 'max_pmts_year_507T', 'mean_pmts_month_706T', 'mean_pmts_year_507T']\n",
      "####### NAN count = 512598\n",
      "Use these ['mean_num_group1_13', 'max_num_group2_13', 'mean_num_group2_13']\n",
      "####### NAN count = 141371\n",
      "['case_id', 'WEEK_NUM', 'target', 'month_decision', 'weekday_decision', 'credamount_770A', 'applicationcnt_361L', 'applications30d_658L', 'applicationscnt_1086L', 'applicationscnt_464L', 'applicationscnt_867L', 'clientscnt_1022L', 'clientscnt_100L', 'clientscnt_1071L', 'clientscnt_1130L', 'clientscnt_157L', 'clientscnt_257L', 'clientscnt_304L', 'clientscnt_360L', 'clientscnt_493L', 'clientscnt_533L', 'clientscnt_887L', 'clientscnt_946L', 'deferredmnthsnum_166L', 'disbursedcredamount_1113A', 'downpmt_116A', 'homephncnt_628L', 'isbidproduct_1095L', 'mobilephncnt_593L', 'numactivecreds_622L', 'numactivecredschannel_414L', 'numactiverelcontr_750L', 'numcontrs3months_479L', 'numnotactivated_1143L', 'numpmtchanneldd_318L', 'numrejects9m_859L', 'sellerplacecnt_915L', 'max_mainoccupationinc_384A', 'max_birth_259D', 'mean_persontype_1072L', 'description_5085714M_cnt', 'education_1103M_cnt', 'maritalst_893M_cnt', 'maritalst_385M_cnt', 'requesttype_4525192L_cnt', 'bankacctype_710L_cnt', 'cardtype_51L_cnt', 'credtype_322L_cnt', 'disbursementtype_67L_cnt', 'equalitydataagreement_891L_cnt', 'isbidproduct_1095L_cnt', 'lastapprcommoditycat_1041M_cnt', 'lastcancelreason_561M_cnt', 'lastrejectcommoditycat_161M_cnt', 'lastrejectcommodtypec_5251769M_cnt', 'lastrejectreason_759M_cnt', 'lastst_736L_cnt', 'paytype1st_925L_cnt', 'twobodfilling_608L_cnt', 'typesuite_864L_cnt', 'max_cancelreason_3545846M_cnt', 'max_education_1138M_cnt', 'max_postype_4733339M_cnt', 'max_credacc_status_367L_cnt', 'max_credtype_587L_cnt', 'max_familystate_726L_cnt', 'max_isbidproduct_390L_cnt', 'max_isdebitcard_527L_cnt', 'max_status_219L_cnt', 'max_collaterals_typeofguarante_669M_cnt', 'max_classificationofcontr_400M_cnt', 'max_contractst_545M_cnt', 'max_contractst_964M_cnt', 'max_financialinstitution_382M_cnt', 'max_financialinstitution_591M_cnt', 'max_purposeofcred_874M_cnt', 'max_subjectrole_93M_cnt', 'max_education_927M_cnt', 'max_empladdr_district_926M_cnt', 'max_language1_981M_cnt', 'max_contaddr_matchlist_1032L_cnt', 'max_contaddr_smempladdr_334L_cnt', 'max_empl_employedtotal_800L_cnt', 'max_empl_industry_691L_cnt', 'max_familystate_447L_cnt', 'max_housetype_905L_cnt', 'max_incometype_1044T_cnt', 'max_role_1084L_cnt', 'max_safeguarantyflag_411L_cnt', 'max_sex_738L_cnt', 'max_type_25L_cnt', 'max_collaterals_typeofguarante_359M_cnt', 'assignmentdate_238D', 'assignmentdate_4527235D', 'pmtaverage_4527227A', 'pmtcount_4527229L', 'birthdate_574D', 'mean_contractsum_5085717L', 'dateofbirth_337D', 'days180_256L', 'days30_165L', 'days360_512L', 'firstquarter_103L', 'fourthquarter_440L', 'secondquarter_766L', 'thirdquarter_1082L', 'max_debtoutstand_525A', 'max_debtoverdue_47A', 'max_refreshdate_3813885D', 'mean_refreshdate_3813885D', 'pmtaverage_3A', 'pmtcount_693L', 'pmtscount_423L', 'pmtssum_45A', 'responsedate_1012D', 'responsedate_4527233D', 'responsedate_4917613D', 'actualdpdtolerance_344P', 'amtinstpaidbefduel24m_4187115A', 'numinstlswithdpd5_4187116L', 'annuitynextmonth_57A', 'currdebt_22A', 'currdebtcredtyperange_828A', 'numinstls_657L', 'totalsettled_863A', 'mindbddpdlast24m_3658935P', 'avgdbddpdlast3m_4187120P', 'mindbdtollast24m_4525191P', 'avgdpdtolclosure24_3658938P', 'avginstallast24m_3658937A', 'maxinstallast24m_3658928A', 'avglnamtstart24m_4525187A', 'avgmaxdpdlast9m_3716943P', 'avgoutstandbalancel6m_4187114A', 'avgpmtlast12m_4525200A', 'cntincpaycont9m_3716944L', 'cntpmts24_3658933L', 'commnoinclast6m_3546845L', 'maxdpdfrom6mto36m_3546853P', 'datefirstoffer_1144D', 'datelastinstal40dpd_247D', 'datelastunpaid_3546854D', 'daysoverduetolerancedd_3976961L', 'numinsttopaygr_769L', 'dtlastpmtallstes_4499206D', 'eir_270L', 'firstclxcampaign_1125D', 'firstdatedue_489D', 'inittransactionamount_650A', 'lastactivateddate_801D', 'lastapplicationdate_877D', 'mean_creationdate_885D', 'mean_isbidproduct_390L', 'max_num_group1', 'lastapprcredamount_781A', 'lastapprdate_640D', 'lastdelinqdate_224D', 'lastrejectcredamount_222A', 'lastrejectdate_50D', 'maininc_215A', 'mastercontrelectronic_519L', 'mastercontrexist_109L', 'maxannuity_159A', 'maxdebt4_972A', 'maxdpdlast24m_143P', 'maxdpdlast3m_392P', 'maxdpdtolerance_374P', 'maxdbddpdlast1m_3658939P', 'maxdbddpdtollast12m_3658940P', 'maxdbddpdtollast6m_4187119P', 'maxdpdinstldate_3546855D', 'maxdpdinstlnum_3546846P', 'maxlnamtstart6m_4525199A', 'maxoutstandbalancel12m_4187113A', 'maxpmtlast3m_4525190A', 'numinstpaidearly_338L', 'numinstpaidearly5d_1087L', 'numinstpaidlate1d_3546852L', 'numincomingpmts_3546848L', 'numinstlsallpaid_934L', 'numinstlswithdpd10_728L', 'numinstlswithoutdpd_562L', 'numinstpaid_4499208L', 'numinstpaidearly3d_3546850L', 'numinstregularpaidest_4493210L', 'numinstpaidearly5dest_4493211L', 'sumoutstandtotalest_4493215A', 'numinstpaidlastcontr_4325080L', 'numinstregularpaid_973L', 'pctinstlsallpaidearl3d_427L', 'pctinstlsallpaidlate1d_3546856L', 'pctinstlsallpaidlat10d_839L', 'pctinstlsallpaidlate4d_3546849L', 'pctinstlsallpaidlate6d_3546844L', 'pmtnum_254L', 'posfpd10lastmonth_333P', 'posfpd30lastmonth_3976960P', 'posfstqpd30lastmonth_3976962P', 'price_1097A', 'sumoutstandtotal_3546847A', 'totaldebt_9A', 'totinstallast1m_4525188A', 'validfrom_1069D', 'mean_actualdpd_943P', 'max_annuity_853A', 'mean_annuity_853A', 'mean_credacc_actualbalance_314A', 'mean_credacc_maxhisbal_375A', 'mean_credacc_minhisbal_90A', 'mean_credacc_transactions_402L', 'max_credacc_credlmt_575A', 'max_credamount_590A', 'max_downpmt_134A', 'mean_credacc_credlmt_575A', 'mean_credamount_590A', 'mean_downpmt_134A', 'max_currdebt_94A', 'mean_currdebt_94A', 'max_mainoccupationinc_437A', 'mean_mainoccupationinc_437A', 'mean_maxdpdtolerance_577P', 'max_outstandingdebt_522A', 'mean_outstandingdebt_522A', 'mean_revolvingaccount_394A', 'max_approvaldate_319D', 'mean_approvaldate_319D', 'max_dateactivated_425D', 'mean_dateactivated_425D', 'max_dtlastpmt_581D', 'mean_dtlastpmt_581D', 'max_dtlastpmtallstes_3545839D', 'mean_dtlastpmtallstes_3545839D', 'max_employedfrom_700D', 'max_firstnonzeroinstldate_307D', 'mean_firstnonzeroinstldate_307D', 'mean_byoccupationinc_3656910L', 'mean_childnum_21L', 'max_pmtnum_8L', 'mean_pmtnum_8L', 'mean_isdebitcard_527L', 'max_amount_4527230A', 'max_recorddate_4527225D', 'max_num_group1_3', 'mean_amount_4917619A', 'max_deductiondate_4917603D', 'mean_deductiondate_4917603D', 'max_num_group1_4', 'max_pmtamount_36A', 'max_processingdate_168D', 'mean_processingdate_168D', 'max_num_group1_5', 'mean_credlmt_230A', 'mean_credlmt_935A', 'mean_pmts_dpd_1073P', 'mean_dpdmaxdatemonth_89T', 'mean_dpdmaxdateyear_596T', 'max_pmts_dpd_303P', 'mean_dpdmax_757P', 'max_dpdmaxdatemonth_442T', 'max_dpdmaxdateyear_896T', 'mean_dpdmaxdatemonth_442T', 'mean_dpdmaxdateyear_896T', 'mean_pmts_dpd_303P', 'mean_instlamount_768A', 'mean_instlamount_852A', 'mean_monthlyinstlamount_332A', 'max_monthlyinstlamount_674A', 'mean_monthlyinstlamount_674A', 'mean_outstandingamount_354A', 'mean_outstandingamount_362A', 'mean_overdueamount_31A', 'mean_overdueamount_659A', 'mean_numberofoverdueinstls_725L', 'mean_overdueamountmax2_14A', 'mean_totaloutstanddebtvalue_39A', 'mean_dateofcredend_289D', 'mean_dateofcredstart_739D', 'max_lastupdate_1112D', 'mean_lastupdate_1112D', 'mean_numberofcontrsvalue_258L', 'mean_numberofoverdueinstlmax_1039L', 'mean_overdueamountmaxdatemonth_365T', 'mean_overdueamountmaxdateyear_2T', 'mean_pmts_overdue_1140A', 'max_pmts_month_158T', 'max_pmts_year_1139T', 'mean_pmts_month_158T', 'mean_pmts_year_1139T', 'mean_overdueamountmax2_398A', 'max_dateofcredend_353D', 'max_dateofcredstart_181D', 'mean_dateofcredend_353D', 'max_numberofoverdueinstlmax_1151L', 'mean_numberofoverdueinstlmax_1151L', 'mean_overdueamountmax_35A', 'max_overdueamountmaxdatemonth_284T', 'max_overdueamountmaxdateyear_994T', 'mean_overdueamountmaxdatemonth_284T', 'mean_overdueamountmaxdateyear_994T', 'mean_pmts_overdue_1152A', 'max_residualamount_488A', 'mean_residualamount_856A', 'max_totalamount_6A', 'mean_totalamount_6A', 'mean_totalamount_996A', 'mean_totaldebtoverduevalue_718A', 'mean_totaloutstanddebtvalue_668A', 'mean_numberofcontrsvalue_358L', 'max_dateofrealrepmt_138D', 'mean_dateofrealrepmt_138D', 'max_lastupdate_388D', 'mean_lastupdate_388D', 'max_numberofoverdueinstlmaxdat_148D', 'mean_numberofoverdueinstlmaxdat_641D', 'mean_overdueamountmax2date_1002D', 'max_overdueamountmax2date_1142D', 'mean_annualeffectiverate_199L', 'mean_annualeffectiverate_63L', 'mean_nominalrate_281L', 'max_nominalrate_498L', 'mean_nominalrate_498L', 'max_numberofinstls_229L', 'mean_numberofinstls_229L', 'mean_numberofinstls_320L', 'mean_numberofoutstandinstls_520L', 'mean_numberofoutstandinstls_59L', 'max_numberofoverdueinstls_834L', 'mean_numberofoverdueinstls_834L', 'max_periodicityofpmts_1102L', 'mean_periodicityofpmts_1102L', 'mean_periodicityofpmts_837L', 'mean_prolongationcount_1120L', 'mean_num_group1_6', 'max_empl_employedfrom_271D', 'mean_contaddr_matchlist_1032L', 'mean_contaddr_smempladdr_334L', 'mean_remitter_829L', 'mean_safeguarantyflag_411L', 'mean_amount_416A', 'mean_openingdate_313D', 'max_num_group1_10', 'mean_openingdate_857D', 'max_num_group1_11', 'mean_collater_valueofguarantee_1124L', 'mean_collater_valueofguarantee_876L', 'max_pmts_month_706T', 'max_pmts_year_507T', 'mean_pmts_month_706T', 'mean_pmts_year_507T', 'mean_num_group1_13', 'max_num_group2_13', 'mean_num_group2_13']\n",
      "352\n",
      "424\n"
     ]
    }
   ],
   "source": [
    "df_train, cat_cols = to_pandas(df_train)\n",
    "df_train = reduce_mem_usage(df_train)\n",
    "print(\"train data shape:\\t\", df_train.shape)\n",
    "nums=df_train.select_dtypes(exclude='category').columns\n",
    "from itertools import combinations, permutations\n",
    "#df_train=df_train[nums]\n",
    "nans_df = df_train[nums].isna()\n",
    "nans_groups={}\n",
    "for col in nums:\n",
    "    cur_group = nans_df[col].sum()\n",
    "    try:\n",
    "        nans_groups[cur_group].append(col)\n",
    "    except:\n",
    "        nans_groups[cur_group]=[col]\n",
    "del nans_df; x=gc.collect()\n",
    "\n",
    "def reduce_group(grps):\n",
    "    use = []\n",
    "    for g in grps:\n",
    "        mx = 0; vx = g[0]\n",
    "        for gg in g:\n",
    "            n = df_train[gg].nunique()\n",
    "            if n>mx:\n",
    "                mx = n\n",
    "                vx = gg\n",
    "            #print(str(gg)+'-'+str(n),', ',end='')\n",
    "        use.append(vx)\n",
    "        #print()\n",
    "    print('Use these',use)\n",
    "    return use\n",
    "\n",
    "def group_columns_by_correlation(matrix, threshold=0.8):\n",
    "    # 计算列之间的相关性\n",
    "    correlation_matrix = matrix.corr()\n",
    "\n",
    "    # 分组列\n",
    "    groups = []\n",
    "    remaining_cols = list(matrix.columns)\n",
    "    while remaining_cols:\n",
    "        col = remaining_cols.pop(0)\n",
    "        group = [col]\n",
    "        correlated_cols = [col]\n",
    "        for c in remaining_cols:\n",
    "            if correlation_matrix.loc[col, c] >= threshold:\n",
    "                group.append(c)\n",
    "                correlated_cols.append(c)\n",
    "        groups.append(group)\n",
    "        remaining_cols = [c for c in remaining_cols if c not in correlated_cols]\n",
    "    \n",
    "    return groups\n",
    "\n",
    "uses=[]\n",
    "for k,v in nans_groups.items():\n",
    "    if len(v)>1:\n",
    "            Vs = nans_groups[k]\n",
    "            #cross_features=list(combinations(Vs, 2))\n",
    "            #make_corr(Vs)\n",
    "            grps= group_columns_by_correlation(df_train[Vs], threshold=0.8)\n",
    "            use=reduce_group(grps)\n",
    "            uses=uses+use\n",
    "            #make_corr(use)\n",
    "    else:\n",
    "        uses=uses+v\n",
    "    print('####### NAN count =',k)\n",
    "print(uses)\n",
    "print(len(uses))\n",
    "uses=uses+list(df_train.select_dtypes(include='category').columns)\n",
    "print(len(uses))\n",
    "df_train=df_train[uses]\n",
    "# df_train.drop(['requesttype_4525192L_cnt','max_empl_employedtotal_800L_cnt', 'max_empl_industry_691L_cnt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2446ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train[\"target\"]\n",
    "weeks = df_train[\"WEEK_NUM\"]\n",
    "df_train= df_train.drop(columns=[\"target\", \"case_id\", \"WEEK_NUM\"])\n",
    "n_splits=5\n",
    "cv = StratifiedGroupKFold(n_splits=n_splits, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9310fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在训练模型后，保存分类特征信息\n",
    "categorical_features = []\n",
    "for col in df_train.columns:\n",
    "    if pd.api.types.is_categorical_dtype(df_train[col]) or df_train[col].dtype == 'object':\n",
    "        categorical_features.append(col)\n",
    "\n",
    "# 保存分类特征列表\n",
    "joblib.dump(categorical_features, '/Users/wuqianran/Desktop/bigdata_finalproject/final/categorical_features.pkl')\n",
    "\n",
    "# 保存数据类型信息\n",
    "joblib.dump(df_train.dtypes, '/Users/wuqianran/Desktop/bigdata_finalproject/final/column_dtypes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ba092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.818329\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.817141\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.823298\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.823715\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.816754\n",
      "CV AUC scores:  [0.8183287976164907, 0.8171405047673326, 0.8232983625757633, 0.8237148323046233, 0.8167539058241644]\n",
      "Maximum CV AUC score:  0.8237148323046233\n"
     ]
    }
   ],
   "source": [
    "# params = {\n",
    "#     \"boosting_type\": \"gbdt\",\n",
    "    \n",
    "#     \"objective\": \"binary\",\n",
    "#     \"metric\": \"auc\",\n",
    "#     \"max_depth\": 8,  \n",
    "#     \"learning_rate\": 0.01,\n",
    "#     \"n_estimators\": 10000,  \n",
    "#     \"colsample_bytree\": 0.8,\n",
    "#     \"colsample_bynode\": 0.8,\n",
    "#     \"verbose\": -1,\n",
    "#     \"random_state\": 42,\n",
    "#     \"reg_alpha\": 0.3,\n",
    "#     \"reg_lambda\": 8,\n",
    "#     \"extra_trees\":True,\n",
    "#     'num_leaves':32,\n",
    "#     \"sample_weight\":'balanced',\n",
    "#     # \"device\": \"cpu\", \n",
    "#     \"device\": \"gpu\", \n",
    "#     \"verbose\": -1,\n",
    "# }\n",
    "# 保存数据类型信息\n",
    "df_train.dtypes.to_frame('dtype').to_csv('/Users/wuqianran/Desktop/bigdata_finalproject/final/column_dtypes.csv')\n",
    "\n",
    "# 保存处理后的数据\n",
    "df_train.to_csv('/Users/wuqianran/Desktop/bigdata_finalproject/final/processed_data.csv', index=False)\n",
    "\n",
    "# 计算并保存每列的平均值\n",
    "column_means = df_train.mean().to_frame('mean')\n",
    "column_means.to_csv('/Users/wuqianran/Desktop/bigdata_finalproject/final/column_means.csv')\n",
    "\n",
    "params = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"max_depth\": 4,  # 降低树的最大深度\n",
    "    \"learning_rate\": 0.05,  # 降低学习率\n",
    "    \"n_estimators\": 100,  # 增加迭代次数\n",
    "    \"colsample_bytree\": 0.6,\n",
    "    \"colsample_bynode\": 0.6,\n",
    "    \"verbose\": -1,\n",
    "    \"random_state\": 42,\n",
    "    \"reg_alpha\": 0.1,  # 增加 L1 正则化\n",
    "    \"reg_lambda\": 1,  # 增加 L2 正则化\n",
    "    \"extra_trees\": True,\n",
    "    'num_leaves': 8,  # 减少叶子节点的数量\n",
    "    \"min_data_in_leaf\": 50,  # 增加每个叶子节点的最小数据量\n",
    "    \"device\": \"cpu\",\n",
    "    # \"device\": \"gpu\",\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "fitted_models = []\n",
    "cv_scores = []\n",
    "best_auc = 0\n",
    "best_model = None\n",
    "\n",
    "for idx_train, idx_valid in cv.split(df_train, y, groups=weeks):#   Because it takes a long time to divide the data set, \n",
    "    X_train, y_train = df_train.iloc[idx_train], y.iloc[idx_train]# each time the data set is divided, two models are trained to each other twice, which saves time.\n",
    "    X_valid, y_valid = df_train.iloc[idx_valid], y.iloc[idx_valid]\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set = [(X_valid, y_valid)],\n",
    "        callbacks = [lgb.log_evaluation(200), lgb.early_stopping(100)] )\n",
    "    fitted_models.append(model)\n",
    "    y_pred_valid = model.predict_proba(X_valid)[:,1]\n",
    "    auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "    cv_scores.append(auc_score)\n",
    "    \n",
    "    # 如果当前模型的 AUC 分数是最好的，则保存该模型\n",
    "    if auc_score > best_auc:\n",
    "        best_auc = auc_score\n",
    "        best_model = model\n",
    "        \n",
    "if best_model is not None:\n",
    "    joblib.dump(best_model, '/Users/wuqianran/Desktop/bigdata_finalproject/final/lgbm_best_model.pkl')\n",
    "\n",
    "lgb_cv_results = pd.DataFrame({\n",
    "    'fold': range(1, n_splits + 1),\n",
    "    'auc_score': cv_scores\n",
    "})\n",
    "lgb_cv_results.to_csv('/Users/wuqianran/Desktop/bigdata_finalproject/final/lgbm_results.csv', index=False)\n",
    "\n",
    "\n",
    "print(\"CV AUC scores: \", cv_scores)\n",
    "print(\"Maximum CV AUC score: \", max(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4025d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/wuqianran/Desktop/bigdata_finalproject/final/column_dtypes.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# 在训练模型后，保存分类特征信息\n",
    "categorical_features = []\n",
    "for col in df_train.columns:\n",
    "    if pd.api.types.is_categorical_dtype(df_train[col]) or df_train[col].dtype == 'object':\n",
    "        categorical_features.append(col)\n",
    "\n",
    "# 保存分类特征列表\n",
    "joblib.dump(categorical_features, '/Users/wuqianran/Desktop/bigdata_finalproject/final/categorical_features.pkl')\n",
    "\n",
    "# 保存数据类型信息\n",
    "joblib.dump(df_train.dtypes, '/Users/wuqianran/Desktop/bigdata_finalproject/final/column_dtypes.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd96958",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train[\"target\"]\n",
    "weeks = df_train[\"WEEK_NUM\"]\n",
    "df_train= df_train.drop(columns=[\"target\", \"case_id\", \"WEEK_NUM\"])\n",
    "df_train[cat_cols] = df_train[cat_cols].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6cb094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "# params = {\n",
    "#     \"eval_metric\": \"AUC\",  \n",
    "#     # \"depth\": 10,  \n",
    "#     \"learning_rate\": 0.03,\n",
    "#     \"iterations\": 6000,  # 4000\n",
    "#     # \"random_seed\": 3107,  \n",
    "#     # \"l2_leaf_reg\": 10,  \n",
    "#     # \"border_count\": 254,  \n",
    "#     \"verbose\": 500,  \n",
    "#     \"task_type\": \"GPU\",\n",
    "#     \"early_stopping_rounds\": 100  # 设置早停机制\n",
    "# }\n",
    "\n",
    "params = {\n",
    "    \"eval_metric\": \"AUC\",  \n",
    "    \"depth\": 6,  # 降低树的最大深度\n",
    "    \"learning_rate\": 0.01,  # 降低学习率\n",
    "    \"iterations\": 3000,  # 减少迭代次数\n",
    "    \"l2_leaf_reg\": 5,  # 增加 L2 正则化\n",
    "    \"verbose\": 500,  \n",
    "    \"task_type\": \"CPU\",\n",
    "    \"early_stopping_rounds\": 100  # 设置早停机制\n",
    "}\n",
    "\n",
    "fitted_models = []\n",
    "cv_scores = []\n",
    "best_auc = 0\n",
    "best_model = None\n",
    "\n",
    "cv = StratifiedGroupKFold(n_splits=n_splits, shuffle=False)\n",
    "\n",
    "step = 0\n",
    "for idx_train, idx_valid in cv.split(df_train, y, groups=weeks):#   Because it takes a long time to divide the data set, \n",
    "    step += 1\n",
    "    print(f'current step: {step}')\n",
    "    \n",
    "    X_train, y_train = df_train.iloc[idx_train], y.iloc[idx_train]# each time the data set is divided, two models are trained to each other twice, which saves time.\n",
    "    X_valid, y_valid = df_train.iloc[idx_valid], y.iloc[idx_valid]\n",
    "\n",
    "    train_pool = Pool(X_train, y_train,cat_features=cat_cols)\n",
    "    val_pool = Pool(X_valid, y_valid,cat_features=cat_cols)\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(train_pool, eval_set=val_pool, verbose=100, early_stopping_rounds=50)\n",
    "\n",
    "    \n",
    "    fitted_models.append(model)\n",
    "    y_pred_valid = model.predict_proba(X_valid)[:,1]\n",
    "    auc_score = roc_auc_score(y_valid, y_pred_valid)\n",
    "    cv_scores.append(auc_score)\n",
    "    \n",
    "    # 如果当前模型的 AUC 分数是最好的，则保存该模型\n",
    "    if auc_score > best_auc:\n",
    "        best_auc = auc_score\n",
    "        best_model = model\n",
    "\n",
    "# 保存最好的模型到文件\n",
    "if best_model is not None:\n",
    "    joblib.dump(best_model, '/Users/wuqianran/Desktop/bigdata_finalproject/final/catboost_best_model.pkl')\n",
    "\n",
    "# 保存训练结果到文件\n",
    "cv_results = pd.DataFrame({\n",
    "    'fold': range(1, n_splits + 1),\n",
    "    'auc_score': cv_scores\n",
    "})\n",
    "cv_results.to_csv('/Users/wuqianran/Desktop/bigdata_finalproject/final/catboost_results.csv', index=False)\n",
    "\n",
    " \n",
    "print(\"CV AUC scores: \", cv_scores)\n",
    "print(\"AVG CV AUC score: \", np.mean(cv_scores))\n",
    "print(\"Maximum CV AUC score: \", max(cv_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
